{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Theory_experiment_mix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqkAidHxnvIxrKah1TRMWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sargyri/Drop_Lev/blob/master/Machine_learning/Theory_experiment_mix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhGuhbZ6M5tl"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "AwOEIRJC6Une"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KyPEtTqk6VdG"
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 Fran√ßois Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Lev Droplet "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBIlTPscrIT9"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/basic_regression\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/tutorials/keras/basic_regression.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/r2.0rc/site/en/tutorials/keras/basic_regression.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHp3M9ZmrIxj"
      },
      "source": [
        "Determination of ST by NN using coords (rho,theta, volume, volt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moB4tpEHxKB3"
      },
      "source": [
        "# Use seaborn for pairplot\n",
        "#!pip install seaborn\n",
        "#!pip install talos\n",
        "#!pip install -q  --no-deps tensorflow-addons~=0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_CJRT6p-bHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49266380-bd36-4606-8d4f-360132767f1e"
      },
      "source": [
        "!pip install lmfit\n",
        "!pip install tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lmfit in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from lmfit) (1.19.5)\n",
            "Requirement already satisfied: asteval>=0.9.16 in /usr/local/lib/python3.7/dist-packages (from lmfit) (0.9.23)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from lmfit) (1.4.1)\n",
            "Requirement already satisfied: uncertainties>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from lmfit) (3.1.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from uncertainties>=3.0.1->lmfit) (0.16.0)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rRo8oNqZ-Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d05ebf-fda1-4372-ff2f-60bfe949c494"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pathlib\n",
        "import pprint\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvCBPgR-gWXl"
      },
      "source": [
        "Run the next code box only if google drive is not mounted to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dA-joJRPNiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5deb60b6-6523-4b90-ab8c-f3269d9ef50d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMshRx3PgwcZ"
      },
      "source": [
        "If it **is** mounted continue from here on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUp-UtJe3dA"
      },
      "source": [
        "Check the connection at google's **GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgZHRBKye0v-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83401890-f2fd-4dc1-f6aa-eca0844d2182"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x6T3kToe53b"
      },
      "source": [
        "**Or** check the connection at google's **TPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IEVK-KFxi5Z"
      },
      "source": [
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh9ne3FZ-On"
      },
      "source": [
        "### Get the data\n",
        "First download the dataset!\n",
        "\n",
        "**Option 1**: Upload files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7-5GSURZTdh"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l83INVYlZsND"
      },
      "source": [
        "import io\n",
        "csvfilename=str('TritonX100_conci_0.0100_all.csv')\n",
        "input = pd.read_csv(io.BytesIO(uploaded[csvfilename]))\n",
        "#input = pd.read_csv(csvfilename, sep=\"\\t\")\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "input.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCobdL9vDRXH"
      },
      "source": [
        "**Option 2**: Import files from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-NFT5ddEOdC"
      },
      "source": [
        "#From the drive folder that is mounted to collab go to the file that you are interested in, \n",
        "#right click and copy the path of the file. Paste it in csvfilename:\n",
        "path=str('/content/drive/My Drive/DropLev/Levitator_2/Training/')\n",
        "\n",
        "fileSDS1=pd.read_csv(str(path+'SDS/SDS_conci_0.01054_all.csv'), sep=\"\\t\")\n",
        "fileSDS2=pd.read_csv(str(path+'SDS/SDS_conci_0.02108_all.csv'), sep='\\t')\n",
        "fileSDS3=pd.read_csv(str(path+'SDS/SDS_conci_0.04273_all.csv'), sep='\\t')\n",
        "fileSDS4=pd.read_csv(str(path+'SDS/SDS_conci_0.08828_all.csv'), sep=\"\\t\")\n",
        "fileSDS5=pd.read_csv(str(path+'SDS/SDS_conci_0.25000_all.csv'), sep=\"\\t\")\n",
        "fileSDS6=pd.read_csv(str(path+'SDS/SDS_conci_0.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS7=pd.read_csv(str(path+'SDS/SDS_conci_0.75000_all.csv'), sep=\"\\t\")\n",
        "fileSDS8=pd.read_csv(str(path+'SDS/SDS_conci_1.00000_all.csv'), sep=\"\\t\")\n",
        "fileSDS9=pd.read_csv(str(path+'SDS/SDS_conci_1.25000_all.csv'), sep=\"\\t\")\n",
        "fileSDS10=pd.read_csv(str(path+'SDS/SDS_conci_1.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS11=pd.read_csv(str(path+'SDS/SDS_conci_2.00000_all.csv'), sep=\"\\t\")\n",
        "fileSDS12=pd.read_csv(str(path+'SDS/SDS_conci_2.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS13=pd.read_csv(str(path+'SDS/SDS_conci_3.00000_all.csv'), sep=\"\\t\")\n",
        "fileSDS14=pd.read_csv(str(path+'SDS/SDS_conci_3.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS15=pd.read_csv(str(path+'SDS/SDS_conci_4.00000_all.csv'), sep=\"\\t\")\n",
        "fileSDS16=pd.read_csv(str(path+'SDS/SDS_conci_4.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS17=pd.read_csv(str(path+'SDS/SDS_conci_5.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS18=pd.read_csv(str(path+'SDS/SDS_conci_6.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS19=pd.read_csv(str(path+'SDS/SDS_conci_7.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS20=pd.read_csv(str(path+'SDS/SDS_conci_8.50000_all.csv'), sep=\"\\t\")\n",
        "fileSDS21=pd.read_csv(str(path+'SDS/SDS_conci_24.75900_all.csv'), sep=\"\\t\")\n",
        "\n",
        "fileTrit1=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.00250_all.csv'), sep=\"\\t\")\n",
        "fileTrit2=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.00500_all.csv'), sep=\"\\t\")\n",
        "fileTrit3=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.00750_all.csv'), sep=\"\\t\")\n",
        "fileTrit4=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.01000_all.csv'), sep=\"\\t\")\n",
        "fileTrit5=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.01500_all.csv'), sep=\"\\t\")\n",
        "fileTrit6=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.02000_all.csv'), sep=\"\\t\")\n",
        "fileTrit7=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.02500_all.csv'), sep=\"\\t\")\n",
        "fileTrit8=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.03500_all.csv'), sep=\"\\t\")\n",
        "fileTrit9=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.05000_all.csv'), sep=\"\\t\")\n",
        "fileTrit10=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.07500_all.csv'), sep=\"\\t\")\n",
        "fileTrit11=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.10000_all.csv'), sep=\"\\t\")\n",
        "fileTrit12=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.12500_all.csv'), sep=\"\\t\")\n",
        "fileTrit13=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.15000_all.csv'), sep=\"\\t\")\n",
        "fileTrit14=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.17500_all.csv'), sep=\"\\t\")\n",
        "fileTrit15=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.20000_all.csv'), sep=\"\\t\")\n",
        "fileTrit16=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.25000_all.csv'), sep=\"\\t\")\n",
        "fileTrit17=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.30000_all.csv'), sep=\"\\t\")\n",
        "fileTrit18=pd.read_csv(str(path+'TritonX100/TritonX_conci_0.45000_all.csv'), sep=\"\\t\")\n",
        "fileTrit19=pd.read_csv(str(path+'TritonX100/TritonX_conci_1.00000_all.csv'), sep=\"\\t\")\n",
        "fileTrit20=pd.read_csv(str(path+'TritonX100/TritonX_conci_3.00000_all.csv'), sep=\"\\t\")\n",
        "fileTrit21=pd.read_csv(str(path+'TritonX100/TritonX_conci_10.00000_all.csv'), sep=\"\\t\")\n",
        "\n",
        "fileCTAB1=pd.read_csv(str(path+'CTAB/CTAB_conci_0.00100_all.csv'), sep=\"\\t\")\n",
        "fileCTAB2=pd.read_csv(str(path+'CTAB/CTAB_conci_0.00200_all.csv'), sep=\"\\t\")\n",
        "fileCTAB3=pd.read_csv(str(path+'CTAB/CTAB_conci_0.00500_all.csv'), sep=\"\\t\")\n",
        "fileCTAB4=pd.read_csv(str(path+'CTAB/CTAB_conci_0.01000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB5=pd.read_csv(str(path+'CTAB/CTAB_conci_0.01500_all.csv'), sep=\"\\t\")\n",
        "fileCTAB6=pd.read_csv(str(path+'CTAB/CTAB_conci_0.05500_all.csv'), sep=\"\\t\")\n",
        "fileCTAB7=pd.read_csv(str(path+'CTAB/CTAB_conci_0.10000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB8=pd.read_csv(str(path+'CTAB/CTAB_conci_0.15000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB9=pd.read_csv(str(path+'CTAB/CTAB_conci_0.20000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB10=pd.read_csv(str(path+'CTAB/CTAB_conci_0.25000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB11=pd.read_csv(str(path+'CTAB/CTAB_conci_0.30000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB12=pd.read_csv(str(path+'CTAB/CTAB_conci_0.40000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB13=pd.read_csv(str(path+'CTAB/CTAB_conci_0.50000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB14=pd.read_csv(str(path+'CTAB/CTAB_conci_0.60000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB15=pd.read_csv(str(path+'CTAB/CTAB_conci_0.70000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB16=pd.read_csv(str(path+'CTAB/CTAB_conci_0.80000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB17=pd.read_csv(str(path+'CTAB/CTAB_conci_0.85000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB18=pd.read_csv(str(path+'CTAB/CTAB_conci_0.90000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB19=pd.read_csv(str(path+'CTAB/CTAB_conci_1.00000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB20=pd.read_csv(str(path+'CTAB/CTAB_conci_5.00000_all.csv'), sep=\"\\t\")\n",
        "fileCTAB21=pd.read_csv(str(path+'CTAB/CTAB_conci_13.15224_all.csv'), sep=\"\\t\")\n",
        "\n",
        "#input=np.vstack([fileSDS1, fileSDS2, fileSDS3, fileSDS4, fileSDS5, fileSDS6, fileSDS7, fileSDS8, fileSDS9, fileSDS10, fileSDS11, \n",
        "                 #fileSDS12, fileSDS13, fileSDS14, fileSDS15, fileSDS16, fileSDS17, fileSDS18, fileSDS19, fileSDS20, fileSDS21,\n",
        "                # fileTrit1, fileTrit2, fileTrit3, fileTrit4, fileTrit5, fileTrit6, fileTrit7, fileTrit8, fileTrit9, fileTrit10, fileTrit11,\n",
        "                # fileTrit12, fileTrit13, fileTrit14, fileTrit15, fileTrit16, fileTrit17, fileTrit18, fileTrit19, fileTrit20, fileTrit21,\n",
        "                # fileCTAB1, fileCTAB2, fileCTAB3, fileCTAB4, fileCTAB5, fileCTAB6, fileCTAB7, fileCTAB8, fileCTAB9, fileCTAB10, fileCTAB11,\n",
        "                # fileCTAB12, fileCTAB13, fileCTAB14, fileCTAB15, fileCTAB16, fileCTAB17, fileCTAB18, fileCTAB19, fileCTAB20, fileCTAB21])\n",
        "# input=np.vstack([fileSDS5, fileSDS6, fileSDS7, fileSDS8, fileSDS9, fileSDS10, fileSDS13, fileSDS14,\n",
        "#                  fileTrit7, fileTrit8, fileTrit9, fileTrit10, fileTrit11,\n",
        "#                  fileCTAB9, fileCTAB10, fileCTAB11, fileCTAB12,fileCTAB13, fileCTAB14])\n",
        "# input.shape\n",
        "\n",
        "#csvfilename=str('/content/drive/My Drive/DropLev/Levitator_2/Training/SDS/SDS_conci_1.50000_ML_data.csv')\n",
        "\n",
        "#input = pd.read_csv(csvfilename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzJI27XdjnCq"
      },
      "source": [
        "# input=np.vstack([fileSDS1, fileSDS2, fileSDS3, fileSDS4, fileSDS5, fileSDS6, fileSDS7,fileSDS8, fileSDS9, fileSDS10, fileSDS11, \n",
        "#                  fileSDS12, fileSDS13, fileSDS14, fileSDS15, fileSDS16, fileSDS17, fileSDS18,fileSDS19, fileSDS20, fileSDS21,\n",
        "#                  fileTrit1, fileTrit2, fileTrit3, fileTrit4, fileTrit5,  fileTrit6, fileTrit7, fileTrit8, fileTrit9, fileTrit10, fileTrit11,\n",
        "#                  fileTrit12, fileTrit13, fileTrit14, fileTrit15, fileTrit16, fileTrit17, fileTrit18, fileTrit19, fileTrit20, fileTrit21,\n",
        "#                  fileCTAB1, fileCTAB2, fileCTAB3, fileCTAB4, fileCTAB5,fileCTAB6, fileCTAB7, fileCTAB8, fileCTAB9, fileCTAB10, fileCTAB11,\n",
        "#                  fileCTAB12, fileCTAB13, fileCTAB14, fileCTAB15, fileCTAB16, fileCTAB17, fileCTAB18, fileCTAB19, fileCTAB20, fileCTAB21])\n",
        "\n",
        "# input=np.vstack([fileSDS1, fileSDS2, fileSDS3, fileSDS4, fileSDS5, fileSDS6, fileSDS7, fileSDS19, fileSDS20, fileSDS21,\n",
        "#                  fileTrit1, fileTrit2, fileTrit3, fileTrit4, fileTrit5, fileTrit17, fileTrit18, fileTrit19, fileTrit20, fileTrit21,\n",
        "#                  fileCTAB1, fileCTAB2, fileCTAB3, fileCTAB4, fileCTAB5, fileCTAB15, fileCTAB16, fileCTAB17, fileCTAB18, fileCTAB19, fileCTAB20, fileCTAB21])\n",
        "\n",
        "input=np.vstack([fileSDS8, fileSDS9, fileSDS10, fileSDS11, fileSDS12, fileSDS13, fileSDS14, fileSDS15, fileSDS16, fileSDS17, fileSDS18,\n",
        "                 fileTrit6, fileTrit7, fileTrit8, fileTrit9, fileTrit10, fileTrit11, fileTrit12, fileTrit13, fileTrit14, fileTrit15, fileTrit16,\n",
        "                 fileCTAB6, fileCTAB7, fileCTAB8, fileCTAB9, fileCTAB10, fileCTAB11, fileCTAB12, fileCTAB13, fileCTAB14])\n",
        "\n",
        "# input=np.vstack([fileSDS8, fileSDS9, fileSDS10, fileSDS11, fileSDS12, fileSDS13,  fileSDS14, fileSDS15, fileSDS16, fileSDS17, \n",
        "#            fileTrit7, fileTrit8, fileTrit9, fileTrit10, fileTrit11,\n",
        "#            fileTrit12, fileTrit13, fileTrit14, fileTrit15,  \n",
        "#            fileCTAB7,fileCTAB8, fileCTAB9, fileCTAB10, fileCTAB11, \n",
        "#            fileCTAB13])\n",
        "\n",
        "# input=fileSDS8\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXBoAZocVdj7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "990cb2fd-f7c6-4437-f915-d7e8f9303e02"
      },
      "source": [
        "column_names=[]\n",
        "\n",
        "for i in range(300):\n",
        "  column_names.append('rho_%d' %i)\n",
        "for i in range(300):\n",
        "  column_names.append('phi_%d' %i)\n",
        "for i in range(300):\n",
        "  column_names.append('theta_%d' %i)\n",
        "column_names.append('height')  #900\n",
        "column_names.append('width')  #901\n",
        "column_names.append('volume')#902\n",
        "column_names.append('R_sph')#903\n",
        "column_names.append('volt')#904\n",
        "column_names.append('Intensity')#905\n",
        "column_names.append('time') #906\n",
        "column_names.append('Power')#907\n",
        "#column_names.append('Ps')\n",
        "#column_names.append('Ps_err')\n",
        "column_names.append('centre_x') #908\n",
        "column_names.append('centre_y') #909\n",
        "column_names.append('surfactant_conc') #910\n",
        "column_names.append('Aspect_Ratio') #911\n",
        "column_names.append('st') #912\n",
        "\n",
        "\n",
        "#raw_dataset = pd.read_csv(csvfilename, sep=\"\\t\")\n",
        "#raw_dataset.columns=column_names\n",
        "\n",
        "\n",
        "raw_dataset = pd.DataFrame(data=input,  columns=column_names) \n",
        "              \n",
        "raw_dataset.shape\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "\n",
        "dataset.centre_y=-dataset.centre_y\n",
        "\n",
        "# for i in range(300):\n",
        "#  dataset.pop('rho_%d' %i)\n",
        "for i in range(300):\n",
        "  dataset.pop('phi_%d' %i)\n",
        "# for i in range(300):\n",
        "#  dataset.pop('theta_%d' %i)\n",
        "dataset.pop(\"height\")\n",
        "dataset.pop(\"width\")\n",
        "# dataset.pop(\"volume\")\n",
        "# dataset.pop(\"R_sph\")\n",
        "dataset.pop('volt')\n",
        "dataset.pop('Intensity')\n",
        "dataset.pop('time')\n",
        "dataset.pop('Power')\n",
        "# dataset.pop('Ps')\n",
        "#dataset.pop('Ps_err')\n",
        "dataset.pop(\"centre_x\")\n",
        "dataset.pop(\"centre_y\")\n",
        "dataset.pop('surfactant_conc')\n",
        "dataset.pop(\"Aspect_Ratio\")\n",
        "\n",
        "\n",
        "dataset.tail()\n",
        "\n",
        "#We keep: volume\tPower\tcentre_y\tAspect_Ratio\tst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rho_0</th>\n",
              "      <th>rho_1</th>\n",
              "      <th>rho_2</th>\n",
              "      <th>rho_3</th>\n",
              "      <th>rho_4</th>\n",
              "      <th>rho_5</th>\n",
              "      <th>rho_6</th>\n",
              "      <th>rho_7</th>\n",
              "      <th>rho_8</th>\n",
              "      <th>rho_9</th>\n",
              "      <th>rho_10</th>\n",
              "      <th>rho_11</th>\n",
              "      <th>rho_12</th>\n",
              "      <th>rho_13</th>\n",
              "      <th>rho_14</th>\n",
              "      <th>rho_15</th>\n",
              "      <th>rho_16</th>\n",
              "      <th>rho_17</th>\n",
              "      <th>rho_18</th>\n",
              "      <th>rho_19</th>\n",
              "      <th>rho_20</th>\n",
              "      <th>rho_21</th>\n",
              "      <th>rho_22</th>\n",
              "      <th>rho_23</th>\n",
              "      <th>rho_24</th>\n",
              "      <th>rho_25</th>\n",
              "      <th>rho_26</th>\n",
              "      <th>rho_27</th>\n",
              "      <th>rho_28</th>\n",
              "      <th>rho_29</th>\n",
              "      <th>rho_30</th>\n",
              "      <th>rho_31</th>\n",
              "      <th>rho_32</th>\n",
              "      <th>rho_33</th>\n",
              "      <th>rho_34</th>\n",
              "      <th>rho_35</th>\n",
              "      <th>rho_36</th>\n",
              "      <th>rho_37</th>\n",
              "      <th>rho_38</th>\n",
              "      <th>rho_39</th>\n",
              "      <th>...</th>\n",
              "      <th>theta_262</th>\n",
              "      <th>theta_263</th>\n",
              "      <th>theta_264</th>\n",
              "      <th>theta_265</th>\n",
              "      <th>theta_266</th>\n",
              "      <th>theta_267</th>\n",
              "      <th>theta_268</th>\n",
              "      <th>theta_269</th>\n",
              "      <th>theta_270</th>\n",
              "      <th>theta_271</th>\n",
              "      <th>theta_272</th>\n",
              "      <th>theta_273</th>\n",
              "      <th>theta_274</th>\n",
              "      <th>theta_275</th>\n",
              "      <th>theta_276</th>\n",
              "      <th>theta_277</th>\n",
              "      <th>theta_278</th>\n",
              "      <th>theta_279</th>\n",
              "      <th>theta_280</th>\n",
              "      <th>theta_281</th>\n",
              "      <th>theta_282</th>\n",
              "      <th>theta_283</th>\n",
              "      <th>theta_284</th>\n",
              "      <th>theta_285</th>\n",
              "      <th>theta_286</th>\n",
              "      <th>theta_287</th>\n",
              "      <th>theta_288</th>\n",
              "      <th>theta_289</th>\n",
              "      <th>theta_290</th>\n",
              "      <th>theta_291</th>\n",
              "      <th>theta_292</th>\n",
              "      <th>theta_293</th>\n",
              "      <th>theta_294</th>\n",
              "      <th>theta_295</th>\n",
              "      <th>theta_296</th>\n",
              "      <th>theta_297</th>\n",
              "      <th>theta_298</th>\n",
              "      <th>theta_299</th>\n",
              "      <th>volume</th>\n",
              "      <th>st</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>156655</th>\n",
              "      <td>0.822386</td>\n",
              "      <td>0.823070</td>\n",
              "      <td>0.823239</td>\n",
              "      <td>0.825227</td>\n",
              "      <td>0.825555</td>\n",
              "      <td>0.824092</td>\n",
              "      <td>0.821238</td>\n",
              "      <td>0.818078</td>\n",
              "      <td>0.817721</td>\n",
              "      <td>0.815634</td>\n",
              "      <td>0.813631</td>\n",
              "      <td>0.813586</td>\n",
              "      <td>0.810163</td>\n",
              "      <td>0.808581</td>\n",
              "      <td>0.807087</td>\n",
              "      <td>0.805554</td>\n",
              "      <td>0.797752</td>\n",
              "      <td>0.781719</td>\n",
              "      <td>0.775103</td>\n",
              "      <td>0.769040</td>\n",
              "      <td>0.763541</td>\n",
              "      <td>0.762256</td>\n",
              "      <td>0.759796</td>\n",
              "      <td>0.758620</td>\n",
              "      <td>0.733620</td>\n",
              "      <td>0.722741</td>\n",
              "      <td>0.716765</td>\n",
              "      <td>0.711439</td>\n",
              "      <td>0.708936</td>\n",
              "      <td>0.704215</td>\n",
              "      <td>0.689382</td>\n",
              "      <td>0.688479</td>\n",
              "      <td>0.680292</td>\n",
              "      <td>0.679033</td>\n",
              "      <td>0.674743</td>\n",
              "      <td>0.671057</td>\n",
              "      <td>0.664661</td>\n",
              "      <td>0.662158</td>\n",
              "      <td>0.660377</td>\n",
              "      <td>0.652095</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.827844</td>\n",
              "      <td>-0.920926</td>\n",
              "      <td>-0.924124</td>\n",
              "      <td>-0.956637</td>\n",
              "      <td>-0.971200</td>\n",
              "      <td>-0.978452</td>\n",
              "      <td>-0.988549</td>\n",
              "      <td>-1.017115</td>\n",
              "      <td>-1.024199</td>\n",
              "      <td>-1.079945</td>\n",
              "      <td>-1.151564</td>\n",
              "      <td>-1.158102</td>\n",
              "      <td>-1.216600</td>\n",
              "      <td>-1.222858</td>\n",
              "      <td>-1.233662</td>\n",
              "      <td>-1.239844</td>\n",
              "      <td>-1.244438</td>\n",
              "      <td>-1.261278</td>\n",
              "      <td>-1.265890</td>\n",
              "      <td>-1.282570</td>\n",
              "      <td>-1.309578</td>\n",
              "      <td>-1.335066</td>\n",
              "      <td>-1.350062</td>\n",
              "      <td>-1.355728</td>\n",
              "      <td>-1.410284</td>\n",
              "      <td>-1.429563</td>\n",
              "      <td>-1.434211</td>\n",
              "      <td>-1.462728</td>\n",
              "      <td>-1.472522</td>\n",
              "      <td>-1.481830</td>\n",
              "      <td>-1.486882</td>\n",
              "      <td>-1.500817</td>\n",
              "      <td>-1.514780</td>\n",
              "      <td>-1.542897</td>\n",
              "      <td>-1.552194</td>\n",
              "      <td>-1.556844</td>\n",
              "      <td>-1.561494</td>\n",
              "      <td>-1.570796</td>\n",
              "      <td>1.764766</td>\n",
              "      <td>38.500904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156656</th>\n",
              "      <td>0.822386</td>\n",
              "      <td>0.823070</td>\n",
              "      <td>0.823239</td>\n",
              "      <td>0.821416</td>\n",
              "      <td>0.821745</td>\n",
              "      <td>0.820293</td>\n",
              "      <td>0.817461</td>\n",
              "      <td>0.818078</td>\n",
              "      <td>0.813982</td>\n",
              "      <td>0.811903</td>\n",
              "      <td>0.813631</td>\n",
              "      <td>0.809883</td>\n",
              "      <td>0.810163</td>\n",
              "      <td>0.808581</td>\n",
              "      <td>0.807087</td>\n",
              "      <td>0.801922</td>\n",
              "      <td>0.797752</td>\n",
              "      <td>0.778296</td>\n",
              "      <td>0.775103</td>\n",
              "      <td>0.769040</td>\n",
              "      <td>0.763541</td>\n",
              "      <td>0.762256</td>\n",
              "      <td>0.759796</td>\n",
              "      <td>0.758620</td>\n",
              "      <td>0.733620</td>\n",
              "      <td>0.722741</td>\n",
              "      <td>0.716765</td>\n",
              "      <td>0.711439</td>\n",
              "      <td>0.708936</td>\n",
              "      <td>0.704215</td>\n",
              "      <td>0.689382</td>\n",
              "      <td>0.685423</td>\n",
              "      <td>0.680292</td>\n",
              "      <td>0.679033</td>\n",
              "      <td>0.674743</td>\n",
              "      <td>0.671057</td>\n",
              "      <td>0.664661</td>\n",
              "      <td>0.662158</td>\n",
              "      <td>0.660377</td>\n",
              "      <td>0.652095</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.816396</td>\n",
              "      <td>-0.910221</td>\n",
              "      <td>-0.917701</td>\n",
              "      <td>-0.950547</td>\n",
              "      <td>-0.960931</td>\n",
              "      <td>-0.968239</td>\n",
              "      <td>-0.982794</td>\n",
              "      <td>-1.007249</td>\n",
              "      <td>-1.014392</td>\n",
              "      <td>-1.077545</td>\n",
              "      <td>-1.149534</td>\n",
              "      <td>-1.156107</td>\n",
              "      <td>-1.214898</td>\n",
              "      <td>-1.221189</td>\n",
              "      <td>-1.232046</td>\n",
              "      <td>-1.238260</td>\n",
              "      <td>-1.242873</td>\n",
              "      <td>-1.259798</td>\n",
              "      <td>-1.264429</td>\n",
              "      <td>-1.281194</td>\n",
              "      <td>-1.308337</td>\n",
              "      <td>-1.333948</td>\n",
              "      <td>-1.349015</td>\n",
              "      <td>-1.354711</td>\n",
              "      <td>-1.409530</td>\n",
              "      <td>-1.428899</td>\n",
              "      <td>-1.433569</td>\n",
              "      <td>-1.462728</td>\n",
              "      <td>-1.472062</td>\n",
              "      <td>-1.481830</td>\n",
              "      <td>-1.486490</td>\n",
              "      <td>-1.500490</td>\n",
              "      <td>-1.514780</td>\n",
              "      <td>-1.542766</td>\n",
              "      <td>-1.552194</td>\n",
              "      <td>-1.556844</td>\n",
              "      <td>-1.561494</td>\n",
              "      <td>-1.570796</td>\n",
              "      <td>1.762896</td>\n",
              "      <td>38.499712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156657</th>\n",
              "      <td>0.822573</td>\n",
              "      <td>0.822786</td>\n",
              "      <td>0.822919</td>\n",
              "      <td>0.823070</td>\n",
              "      <td>0.823426</td>\n",
              "      <td>0.823852</td>\n",
              "      <td>0.822092</td>\n",
              "      <td>0.822457</td>\n",
              "      <td>0.823657</td>\n",
              "      <td>0.822217</td>\n",
              "      <td>0.818954</td>\n",
              "      <td>0.818713</td>\n",
              "      <td>0.813982</td>\n",
              "      <td>0.814799</td>\n",
              "      <td>0.809142</td>\n",
              "      <td>0.807522</td>\n",
              "      <td>0.805990</td>\n",
              "      <td>0.803189</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.799657</td>\n",
              "      <td>0.798659</td>\n",
              "      <td>0.794785</td>\n",
              "      <td>0.785676</td>\n",
              "      <td>0.764862</td>\n",
              "      <td>0.759796</td>\n",
              "      <td>0.753192</td>\n",
              "      <td>0.748320</td>\n",
              "      <td>0.745215</td>\n",
              "      <td>0.743564</td>\n",
              "      <td>0.742796</td>\n",
              "      <td>0.716970</td>\n",
              "      <td>0.706155</td>\n",
              "      <td>0.701666</td>\n",
              "      <td>0.694930</td>\n",
              "      <td>0.692980</td>\n",
              "      <td>0.689382</td>\n",
              "      <td>0.674710</td>\n",
              "      <td>0.674743</td>\n",
              "      <td>0.667790</td>\n",
              "      <td>0.667122</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.741947</td>\n",
              "      <td>-0.757954</td>\n",
              "      <td>-0.808650</td>\n",
              "      <td>-0.861586</td>\n",
              "      <td>-0.887701</td>\n",
              "      <td>-0.902728</td>\n",
              "      <td>-0.913481</td>\n",
              "      <td>-0.992894</td>\n",
              "      <td>-1.017115</td>\n",
              "      <td>-1.024199</td>\n",
              "      <td>-1.038292</td>\n",
              "      <td>-1.045301</td>\n",
              "      <td>-1.059240</td>\n",
              "      <td>-1.086790</td>\n",
              "      <td>-1.093606</td>\n",
              "      <td>-1.151564</td>\n",
              "      <td>-1.216600</td>\n",
              "      <td>-1.276562</td>\n",
              "      <td>-1.282570</td>\n",
              "      <td>-1.293157</td>\n",
              "      <td>-1.299080</td>\n",
              "      <td>-1.303703</td>\n",
              "      <td>-1.320031</td>\n",
              "      <td>-1.324659</td>\n",
              "      <td>-1.339706</td>\n",
              "      <td>-1.365013</td>\n",
              "      <td>-1.390097</td>\n",
              "      <td>-1.404872</td>\n",
              "      <td>-1.409530</td>\n",
              "      <td>-1.462728</td>\n",
              "      <td>-1.481830</td>\n",
              "      <td>-1.486490</td>\n",
              "      <td>-1.514780</td>\n",
              "      <td>-1.524101</td>\n",
              "      <td>-1.533604</td>\n",
              "      <td>-1.538250</td>\n",
              "      <td>-1.552194</td>\n",
              "      <td>-1.566145</td>\n",
              "      <td>1.768315</td>\n",
              "      <td>38.503163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156658</th>\n",
              "      <td>0.816622</td>\n",
              "      <td>0.817186</td>\n",
              "      <td>0.817338</td>\n",
              "      <td>0.817902</td>\n",
              "      <td>0.819198</td>\n",
              "      <td>0.815699</td>\n",
              "      <td>0.817955</td>\n",
              "      <td>0.814972</td>\n",
              "      <td>0.815573</td>\n",
              "      <td>0.811311</td>\n",
              "      <td>0.809198</td>\n",
              "      <td>0.807171</td>\n",
              "      <td>0.807080</td>\n",
              "      <td>0.803610</td>\n",
              "      <td>0.802007</td>\n",
              "      <td>0.804156</td>\n",
              "      <td>0.798909</td>\n",
              "      <td>0.794612</td>\n",
              "      <td>0.778308</td>\n",
              "      <td>0.775011</td>\n",
              "      <td>0.768833</td>\n",
              "      <td>0.761904</td>\n",
              "      <td>0.760626</td>\n",
              "      <td>0.758179</td>\n",
              "      <td>0.757011</td>\n",
              "      <td>0.732146</td>\n",
              "      <td>0.721336</td>\n",
              "      <td>0.715399</td>\n",
              "      <td>0.710114</td>\n",
              "      <td>0.707627</td>\n",
              "      <td>0.702939</td>\n",
              "      <td>0.691228</td>\n",
              "      <td>0.687334</td>\n",
              "      <td>0.682313</td>\n",
              "      <td>0.681101</td>\n",
              "      <td>0.673345</td>\n",
              "      <td>0.667048</td>\n",
              "      <td>0.664653</td>\n",
              "      <td>0.662890</td>\n",
              "      <td>0.654785</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.829685</td>\n",
              "      <td>-0.841003</td>\n",
              "      <td>-0.915101</td>\n",
              "      <td>-0.940452</td>\n",
              "      <td>-0.947797</td>\n",
              "      <td>-0.962433</td>\n",
              "      <td>-0.969723</td>\n",
              "      <td>-0.979906</td>\n",
              "      <td>-1.008631</td>\n",
              "      <td>-1.015757</td>\n",
              "      <td>-1.071856</td>\n",
              "      <td>-1.143962</td>\n",
              "      <td>-1.209439</td>\n",
              "      <td>-1.214041</td>\n",
              "      <td>-1.226621</td>\n",
              "      <td>-1.231232</td>\n",
              "      <td>-1.237463</td>\n",
              "      <td>-1.254426</td>\n",
              "      <td>-1.259053</td>\n",
              "      <td>-1.275859</td>\n",
              "      <td>-1.301789</td>\n",
              "      <td>-1.328725</td>\n",
              "      <td>-1.343818</td>\n",
              "      <td>-1.348488</td>\n",
              "      <td>-1.403695</td>\n",
              "      <td>-1.423197</td>\n",
              "      <td>-1.428565</td>\n",
              "      <td>-1.457272</td>\n",
              "      <td>-1.467150</td>\n",
              "      <td>-1.476514</td>\n",
              "      <td>-1.481202</td>\n",
              "      <td>-1.495644</td>\n",
              "      <td>-1.509696</td>\n",
              "      <td>-1.538021</td>\n",
              "      <td>-1.547381</td>\n",
              "      <td>-1.552063</td>\n",
              "      <td>-1.556746</td>\n",
              "      <td>-1.566113</td>\n",
              "      <td>1.753342</td>\n",
              "      <td>38.493602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156659</th>\n",
              "      <td>0.816649</td>\n",
              "      <td>0.817338</td>\n",
              "      <td>0.817508</td>\n",
              "      <td>0.818125</td>\n",
              "      <td>0.815699</td>\n",
              "      <td>0.816030</td>\n",
              "      <td>0.814595</td>\n",
              "      <td>0.811797</td>\n",
              "      <td>0.812419</td>\n",
              "      <td>0.808375</td>\n",
              "      <td>0.806309</td>\n",
              "      <td>0.808049</td>\n",
              "      <td>0.804329</td>\n",
              "      <td>0.804638</td>\n",
              "      <td>0.799403</td>\n",
              "      <td>0.801596</td>\n",
              "      <td>0.796479</td>\n",
              "      <td>0.792391</td>\n",
              "      <td>0.773169</td>\n",
              "      <td>0.770040</td>\n",
              "      <td>0.764051</td>\n",
              "      <td>0.758632</td>\n",
              "      <td>0.757368</td>\n",
              "      <td>0.754950</td>\n",
              "      <td>0.753796</td>\n",
              "      <td>0.729203</td>\n",
              "      <td>0.718531</td>\n",
              "      <td>0.712674</td>\n",
              "      <td>0.707472</td>\n",
              "      <td>0.705017</td>\n",
              "      <td>0.700395</td>\n",
              "      <td>0.688896</td>\n",
              "      <td>0.685052</td>\n",
              "      <td>0.680123</td>\n",
              "      <td>0.678949</td>\n",
              "      <td>0.671387</td>\n",
              "      <td>0.665181</td>\n",
              "      <td>0.662890</td>\n",
              "      <td>0.661144</td>\n",
              "      <td>0.653219</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.833346</td>\n",
              "      <td>-0.848653</td>\n",
              "      <td>-0.922528</td>\n",
              "      <td>-0.947797</td>\n",
              "      <td>-0.955124</td>\n",
              "      <td>-0.969723</td>\n",
              "      <td>-0.972671</td>\n",
              "      <td>-0.987120</td>\n",
              "      <td>-1.015757</td>\n",
              "      <td>-1.022858</td>\n",
              "      <td>-1.078747</td>\n",
              "      <td>-1.150551</td>\n",
              "      <td>-1.214041</td>\n",
              "      <td>-1.220349</td>\n",
              "      <td>-1.231232</td>\n",
              "      <td>-1.237463</td>\n",
              "      <td>-1.242085</td>\n",
              "      <td>-1.259053</td>\n",
              "      <td>-1.265161</td>\n",
              "      <td>-1.280501</td>\n",
              "      <td>-1.307712</td>\n",
              "      <td>-1.333384</td>\n",
              "      <td>-1.348488</td>\n",
              "      <td>-1.353168</td>\n",
              "      <td>-1.408384</td>\n",
              "      <td>-1.428565</td>\n",
              "      <td>-1.433246</td>\n",
              "      <td>-1.461964</td>\n",
              "      <td>-1.471830</td>\n",
              "      <td>-1.481202</td>\n",
              "      <td>-1.485895</td>\n",
              "      <td>-1.500325</td>\n",
              "      <td>-1.514386</td>\n",
              "      <td>-1.542701</td>\n",
              "      <td>-1.552063</td>\n",
              "      <td>-1.556746</td>\n",
              "      <td>-1.561429</td>\n",
              "      <td>-1.570796</td>\n",
              "      <td>1.750045</td>\n",
              "      <td>38.491487</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 602 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           rho_0     rho_1     rho_2  ...  theta_299    volume         st\n",
              "156655  0.822386  0.823070  0.823239  ...  -1.570796  1.764766  38.500904\n",
              "156656  0.822386  0.823070  0.823239  ...  -1.570796  1.762896  38.499712\n",
              "156657  0.822573  0.822786  0.822919  ...  -1.566145  1.768315  38.503163\n",
              "156658  0.816622  0.817186  0.817338  ...  -1.566113  1.753342  38.493602\n",
              "156659  0.816649  0.817338  0.817508  ...  -1.570796  1.750045  38.491487\n",
              "\n",
              "[5 rows x 602 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaNUMVadnhCQ"
      },
      "source": [
        "### Selectively choose data with (almost) constant volume"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrMpqWF0k2ft"
      },
      "source": [
        "# new_input=[]\n",
        "# vol_min=2.99\n",
        "# vol_max=3.01\n",
        "# for i in range(len(dataset)):\n",
        "#   if dataset['volume'].iloc[i] >= vol_min and dataset['volume'].iloc[i] <= vol_max:\n",
        "#     vol_ct_data=dataset.iloc[i, :]\n",
        "#     new_input.append(vol_ct_data)\n",
        "# new_input=np.asarray(new_input)\n",
        "# new_input.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH2AdDoKcM84"
      },
      "source": [
        "# column_names=[]\n",
        "\n",
        "# for i in range(300):\n",
        "#   column_names.append('rho_%d' %i)\n",
        "# for i in range(300):\n",
        "#   column_names.append('theta_%d' %i)\n",
        "# column_names.append('volume')\n",
        "# column_names.append('R_sph')\n",
        "# column_names.append('volt')\n",
        "# column_names.append('st')\n",
        "\n",
        "# new_dataset=pd.DataFrame(new_input, columns=column_names)\n",
        "# new_dataset.pop('R_sph')\n",
        "# new_dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3mgXVPxqhdg"
      },
      "source": [
        "# plt.figure()\n",
        "# sns.distplot(new_dataset['volt'])\n",
        "# plt.xlabel('Voltage [V]')\n",
        "# plt.ylabel('Count')\n",
        "\n",
        "# plt.figure()\n",
        "# sns.distplot(new_dataset['st'])\n",
        "# plt.xlabel('Surface tension [mN/m]')\n",
        "# plt.ylabel('Count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4d1JSJHjQlu"
      },
      "source": [
        "# #Drop volume if it's constant\n",
        "# new_dataset.pop('volume')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESjR-Vr9gz-O"
      },
      "source": [
        "### Calculate the acoustic pressure from the simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSbdYAlnp9dR"
      },
      "source": [
        "new_input=np.asarray(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3EaaZ2thySH"
      },
      "source": [
        "# If no contour points were droped\n",
        "n_ST=603\n",
        "n_Rsph=602\n",
        "rho_i=0\n",
        "rho_f=300\n",
        "theta_i=300\n",
        "theta_f=600"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j12KuanmwH2y"
      },
      "source": [
        "from lmfit import Model, fit_report, Parameters\n",
        "\n",
        "def model_fit(th, Ps):\n",
        "    \"\"\"\n",
        "    Express the model that will be used to fit the experimental data (simple approach).\n",
        "\n",
        "    Input parameters\n",
        "    ----------\n",
        "    dB:     deciBell\n",
        "    th:     angle theta\n",
        "    Returns\n",
        "    -------\n",
        "    Expression of fitting model.\n",
        "\n",
        "    \"\"\"\n",
        "    rho=-((3/(64*gamma))*R_sph**2*Ps**2*Cg_air*(1+((7/5)*(k_o*R_sph)**2)))*(3*(np.cos(th))**2-1)+R_sph\n",
        "    return rho\n",
        "\n",
        "\n",
        "data_Ps=[]\n",
        "Cg_air=1/101325 #Pa**(-1)\n",
        "k_o=2*np.pi*40/340 #mm^-1\n",
        "\n",
        "for i in range(len(new_input)):\n",
        "  gamma=new_input[i, n_ST]\n",
        "  R_sph=new_input[i, n_Rsph]\n",
        "  rho=new_input[i, rho_s, rho_e]\n",
        "  gmodel = Model(model_fit, nan_policy='omit')\n",
        "    \n",
        "  fit_param = Parameters()\n",
        "  fit_param.add('Ps', value=700, min=10, max=4000)\n",
        "  \n",
        "  result = gmodel.fit(rho, th=new_input[i, theta_i:theta_f], params=fit_param)         #rho_final, th: x and y to be evaluated, respectively\n",
        "  Ps=result.params['Ps'].value\n",
        "  data_Ps.append(Ps)\n",
        "data_Ps=np.asarray(data_Ps)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(data_Ps)\n",
        "plt.xlabel('Image')\n",
        "plt.ylabel('Acoustic pressure [Pa]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH8GWcqMpSj5"
      },
      "source": [
        "#### Check the fitting of the simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW-0aq4TFQhw"
      },
      "source": [
        "i=100\n",
        "plt.figure()\n",
        "plt.plot(new_input[i, 300:600], rho, 'bo')\n",
        "plt.plot(new_input[i, 300:600], result.best_fit, 'r-', label='best fit')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vjS9VIDE8IZ"
      },
      "source": [
        "column_names=[]\n",
        "\n",
        "for i in range(300):\n",
        "  column_names.append('rho_%d' %i)\n",
        "for i in range(300):\n",
        "  column_names.append('theta_%d' %i)\n",
        "column_names.append('volume')\n",
        "column_names.append('R_sph')\n",
        "column_names.append('volt')\n",
        "column_names.append('st')\n",
        "\n",
        "new_dataset=pd.DataFrame(new_input, columns=column_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd01bD1bQv37"
      },
      "source": [
        "# #Add the calclulated Ps values to the new_dataset dataframe\n",
        "new_dataset['Ps']=data_Ps\n",
        "\n",
        "#Drop the features that we don't have in the saved model\n",
        "new_dataset.pop('R_sph')\n",
        "new_dataset.pop('volt')\n",
        "# new_dataset.pop('volume')\n",
        "new_dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spvklCeMmQMo"
      },
      "source": [
        "### Drop contour points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4anqOb6ofqwS"
      },
      "source": [
        "dataset=new_dataset.copy()\n",
        "\n",
        "# If we want to drop 150 datapoints then n= 299 \n",
        "\n",
        "# If we want to drop 150 datapoints then n= 250\n",
        "\n",
        "n=250\n",
        "for i in range(0, n, 2):\n",
        "  dataset.pop('theta_%d' %i)\n",
        "\n",
        "for i in range(0,n, 2):\n",
        "  dataset.pop('rho_%d' %i)\n",
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfxngOiQmWQO"
      },
      "source": [
        "def pol2cart(rho, phi):\n",
        "    x = rho * np.cos(phi)\n",
        "    y = rho * np.sin(phi)\n",
        "    return(x, y)\n",
        "\n",
        "#Check that the drop contour is still well defined!\n",
        "\n",
        "# For 150 contour datapoints:\n",
        "# plt.figure()\n",
        "# plt.plot(dataset.iloc[600, 150:300], dataset.iloc[600, 0:150])\n",
        "\n",
        "\n",
        "# For 175 contour datapoints:\n",
        "n=200\n",
        "plt.figure()\n",
        "plt.plot(dataset.iloc[n, 175:350], dataset.iloc[n, 0:175], '-o')\n",
        "\n",
        "x, y=pol2cart(dataset.iloc[n, 0:175].values, dataset.iloc[n, 175:350].values)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x, y, '-o')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX8n2u3TnAL6"
      },
      "source": [
        "### Keep Ps values within a specific range"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bggWFmt2NibH"
      },
      "source": [
        "# newer_input=[]\n",
        "# Ps_min=1500\n",
        "# Ps_max=2100\n",
        "# for i in range(len(new_dataset)):\n",
        "#   if new_dataset['Ps'].iloc[i] >= Ps_min and new_dataset['Ps'].iloc[i] <= Ps_max:\n",
        "#     Ps_range=new_dataset.iloc[i, :]\n",
        "#     newer_input.append(Ps_range)\n",
        "# newer_input=np.asarray(newer_input)\n",
        "\n",
        "# newer_input.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2qMP-VUQLBk"
      },
      "source": [
        "# plt.figure()\n",
        "# plt.plot(newer_input[:, 601])\n",
        "# plt.ylabel('Acoustic pressure [Pa]')\n",
        "# plt.xlabel('droplet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCV02oPCnHSK"
      },
      "source": [
        "### Store values in new DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quLwjCQHOtsw"
      },
      "source": [
        "# column_names=[]\n",
        "\n",
        "# for i in range(300):\n",
        "#   column_names.append('rho_%d' %i)\n",
        "# for i in range(300):\n",
        "#   column_names.append('theta_%d' %i)\n",
        "# # column_names.append('volume')\n",
        "# column_names.append('st')\n",
        "# column_names.append('Ps')\n",
        "\n",
        "# new_df=pd.DataFrame(newer_input, columns=column_names)\n",
        "\n",
        "# #Drop ST:\n",
        "# new_df.pop('st')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### Split the data into train and test\n",
        "\n",
        "Now split the dataset into a training set and a test set.\n",
        "\n",
        "We will use the test set in the final evaluation of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn-IGhUE7_1H"
      },
      "source": [
        "# train_dataset = dataset.sample(frac=0.8,random_state=1)\n",
        "# test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gavKO_6DWRMP"
      },
      "source": [
        "Also look at the overall statistics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M94e1UYNCvW7"
      },
      "source": [
        "# # dataset.pop('st')\n",
        "\n",
        "# dataset_name=dataset.iloc[80000:90000]\n",
        "\n",
        "# stats_input_df=dataset_name.describe()\n",
        "# stats_input_df=stats_input_df.transpose()\n",
        "# stats_input_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi2FzC3T21jR"
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"st\")\n",
        "\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgkRM6C3geh8"
      },
      "source": [
        "# new_dataset.iloc[:, 601]\n",
        "# newer_input=np.asarray(new_dataset.iloc[80000:90000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g7cjfYsnRh5"
      },
      "source": [
        "### Normalize values, Import model and test predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G14I_viqS7D"
      },
      "source": [
        "# def norm_test(x):\n",
        "#   return (x - stats_input_df['mean']) / stats_input_df['std']\n",
        "\n",
        "# #import model from drive\n",
        "# folder=str('theory_experiment_mix/')\n",
        "# filename=str('All_surf_all_vary_175points_trial_1.h5')\n",
        "# model = tf.keras.models.load_model('/content/drive/My Drive/DropLev/MachineLearningModels/'+folder+filename)\n",
        "# model.summary()\n",
        "\n",
        "# norm_input_array=norm_test(dataset_name)\n",
        "# prediction=model.predict(norm_input_array).flatten()\n",
        "# true_values=newer_input[:, 601]\n",
        "\n",
        "# plt.figure()\n",
        "# plt.xlabel('Frame number')\n",
        "# plt.ylabel('Surface tension [ mN/m ]')\n",
        "# plt.ylim(20, 75)\n",
        "# plt.plot(prediction, label='Predicted values')\n",
        "# plt.plot(true_values, label='Real values')\n",
        "# plt.legend()\n",
        "\n",
        "# plt.figure()\n",
        "# plt.scatter(true_values, prediction)\n",
        "# plt.title('Normalized new test data')\n",
        "# plt.xlabel('True Values [surface tension - mN/m]')\n",
        "# plt.ylabel('Predictions [surface tension - mN/m]')\n",
        "# plt.axis('equal')\n",
        "# plt.axis('square')\n",
        "# plt.xlim([10,75])\n",
        "# plt.ylim([10,75])\n",
        "# _ = plt.plot([-100, 100], [-100, 100])\n",
        "# plt.show()\n",
        "\n",
        "# error = prediction - true_values\n",
        "# plt.figure()\n",
        "# plt.hist(error, bins = 50)\n",
        "# plt.xlabel(\"Prediction Error [mN/m]\")\n",
        "# _ = plt.ylabel(\"Count\")\n",
        "# #plt.ylim(0, 30)\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "Train the model for 1000 epochs, and record the training and validation accuracy in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD7qHCmNIOY0"
      },
      "source": [
        "# Display training progress by printing a single dot for each completed epoch\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 55 == 0: print('')\n",
        "    print('.', end='')\n",
        "    \n",
        "\n",
        "\n",
        "EPOCHS = 200\n",
        "\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',min_delta=0, patience=15, verbose=0, mode='auto')\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[early_stop, PrintDot()])  # callbacks=callbacks_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Visualize the model's training progress using the stats stored in the `history` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xj91b-dymEy"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqsuANc11FYv"
      },
      "source": [
        "Let's automatically stop training when the validation score doesn't improve. We'll use an *EarlyStopping callback* that tests a training condition for  every epoch. If a set amount of epochs elapses without showing improvement, then automatically stop the training.\n",
        "\n",
        "You can learn more about this callback [here](https://www.tensorflow.org/versions/master/api_docs/python/tf/keras/callbacks/EarlyStopping)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6XriGbVPh2t"
      },
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [ST]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Training Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Validation Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$ST^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Training Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Validation Error')\n",
        "  plt.ylim([0,40])\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "Let's see how well the model generalizes by using the **test** set, which we did not use when training the model.  This tells us how well we can expect the model to predict when we use it in the real world."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl_yNr5n1kms"
      },
      "source": [
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=0)\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} mN/m\".format(mae))\n",
        "# keras.metrics.accuracy(normed_test_data, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft603OzXuEZC"
      },
      "source": [
        "### Make predictions\n",
        "\n",
        "Finally, predict volume values using data in the testing set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe7RXH3N3CWU"
      },
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.title('Normalized test data')\n",
        "plt.xlabel('True Values [surface tension - mN/m]')\n",
        "plt.ylabel('Predictions [surface tension - mN/m]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([20,75])\n",
        "plt.ylim([20,75])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n",
        "plt.show()\n",
        "\n",
        "test_predictions2 = model.predict(normed_train_data).flatten()\n",
        "\n",
        "plt.scatter(train_labels, test_predictions2)\n",
        "plt.title('Normalized training data')\n",
        "plt.xlabel('True Values [surface tension - mN/m]')\n",
        "plt.ylabel('Predictions [surface tension - mN/m]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([20,75])\n",
        "plt.ylim([20,75])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-OHX4DiXd8x"
      },
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 50)\n",
        "plt.xlabel(\"Prediction Error [surface tension - mN/m]\")\n",
        "_ = plt.ylabel(\"Count\")\n",
        "# plt.xlim(-20, 20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-i0Bq5JF0nv"
      },
      "source": [
        "# Saving the final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8FBhOnbGK65"
      },
      "source": [
        "When you are satisfied with the model and the accuracy continue from here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BspL3Z6-GPaa"
      },
      "source": [
        "Saving the model in a **SavedModel** format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwWrwBcZGLnZ"
      },
      "source": [
        "!pip install -q pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BR7rbL5GXku"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzumSsZfGYCp"
      },
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "folder=str('Experimental_surfactants/')\n",
        "filename=str('TritonX_all_vary_175points_trial_2.h5')\n",
        "!mkdir -p '/content/drive/My Drive/DropLev/MachineLearningModels' #Ceates a folder named \"MachineLearningModels\"\n",
        "model.save('/content/drive/My Drive/DropLev/MachineLearningModels/'+folder+filename)  #Saves the file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJzKbb1EGgUE"
      },
      "source": [
        "The SavedModel format is a directory containing a protobuf binary and a Tensorflow checkpoint. Inspect the saved model directory:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yGUiOkfGgen"
      },
      "source": [
        "# DropLev_st_prediction_model directory\n",
        "#!ls content/drive/My Drive/DropLev/MachineLearningModels\n",
        "\n",
        "# Contains an assets folder, saved_model.pb, and variables folder.\n",
        "#!ls content/drive/My Drive/DropLev/MachineLearningModels/SDS_1.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2IWIiOYGgqK"
      },
      "source": [
        "Saving the model in a **HDF5** format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Zl4tVVGg3J"
      },
      "source": [
        "# Save the entire model to a HDF5 file.\n",
        "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
        "#model.save('content/drive/My Drive/DropLev/MachineLearningModels/'+filename) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}